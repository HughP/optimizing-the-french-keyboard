{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read in: characters, keyslots and letters\n",
      "read in: similarity values\n",
      "read in: distance values\n",
      "read in: probability values\n",
      "´d composes í\n",
      "´d composes á\n",
      "^d composes ê\n",
      "^d composes ô\n",
      "^d composes û\n",
      "^d composes î\n",
      "^d composes â\n",
      "¨d composes ï\n",
      "¨d composes ö\n",
      "¨d composes ü\n",
      "¨d composes ë\n",
      "read in: ergonomics, performance\n",
      "Done reading input values.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from read_input import * \n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "PYTHONIOENCODING=\"utf-8\"\n",
    "\n",
    "level_cost = {u'':0, u'Shift':1, u'Alt':2, u'Alt_Shift':3}\n",
    "w_P = 0.25\n",
    "w_A = 0.25\n",
    "w_F = 0.25\n",
    "w_E = 0.25\n",
    "#Read in model\n",
    "print \"read in: characters, keyslots and letters\"\n",
    "azerty = get_azerty()\n",
    "letters = get_letters()\n",
    "characters = get_characters()\n",
    "keyslots = get_keyslots()\n",
    "\n",
    "print \"read in: similarity values\"\n",
    "similarity_c_c = get_character_similarities()\n",
    "similarity_c_l = get_character_letter_similarities()\n",
    "\n",
    "print \"read in: distance values\"    \n",
    "distance_level_0, distance_level_1 = get_distances(level_cost)\n",
    "\n",
    "#read in  probabilities\n",
    "print \"read in: probability values\" \n",
    "p_single, p_bigram = get_probabilities()\n",
    "print \"read in: ergonomics, performance\" \n",
    "ergonomics = get_ergonomics()\n",
    "performance = get_performance()\n",
    "\n",
    "print \"Done reading input values.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1. compute the linear cost\n",
    "#for each linear variable x[c,s] compute the P, A, F and E term (if it is chosen)\n",
    "x_P = {} \n",
    "x_A = {} \n",
    "x_F = {} \n",
    "x_E = {} \n",
    "\n",
    "for c in characters: \n",
    "    for s in keyslots: \n",
    "        P=0\n",
    "        A=0\n",
    "        #if that character was previously not on azerty, distance is 0.\n",
    "        F = p_single[c] * distance_level_1.get((s, azerty.get(c,\"NaN\")),0)\n",
    "        E=0\n",
    "        for l in letters:\n",
    "            #update performance\n",
    "            if (c,l) in p_bigram:\n",
    "                P += (p_bigram[(c,l)]*performance[(s,azerty[l])]) \n",
    "            if (l,c) in p_bigram:\n",
    "                P += (p_bigram[(l,c)]*performance[(azerty[l],s)])            \n",
    "            #update association\n",
    "            if (c,l) in similarity_c_l:\n",
    "                A += (p_single[c] + p_single[l])*similarity_c_l[(c,l)]*distance_level_0[s,azerty[l]]    \n",
    "            #update ergonomics\n",
    "            if (c,l) in p_bigram:                \n",
    "                E += (p_bigram[(c,l)]*ergonomics[(s,azerty[l])])\n",
    "            if (l,c) in p_bigram:\n",
    "                E += (p_bigram[(l,c)]*ergonomics[(azerty[l],s)])\n",
    "        x_P[c,s] = P\n",
    "        x_A[c,s] = A\n",
    "        x_F[c,s] = F\n",
    "        x_E[c,s] = E\n",
    "#now normalize these terms such that they are all between 0 and 1\n",
    "def normalize_dict_values(d):\n",
    "    maximum = np.max(d.values())\n",
    "    minimum = np.min(d.values())\n",
    "    \n",
    "    for k, v in d.iteritems():\n",
    "        d[k] = v / float(maximum - minimum)\n",
    "    return d\n",
    "\n",
    "x_P = normalize_dict_values(x_P)\n",
    "x_A = normalize_dict_values(x_A)\n",
    "x_F = normalize_dict_values(x_F)\n",
    "x_E = normalize_dict_values(x_E)\n",
    "    \n",
    "#weighted sum of linear terms\n",
    "linear_cost = {}\n",
    "for c in characters: \n",
    "    for s in keyslots:\n",
    "        linear_cost[c,s] = w_P * x_P[c,s] + w_A*x_A[c,s] + w_F*x_F[c,s] + w_E*x_E[c,s]         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#Writes an input file for the reformualtion of the quadratic term\n",
    "f = codecs.open(\"reformulation_input.txt\", 'w', encoding=\"utf-8\")\n",
    "f.write(\"# number of letters and keys\\n\")\n",
    "f.write(str(len(keyslots))+\"\\n\")\n",
    "f.write(\"# w_A*probabilities*similarities\\n\")\n",
    "for c1 in characters:\n",
    "    prob_strings = []\n",
    "    for c2 in characters:\n",
    "        if(c1,c2) in similarity_c_c.keys():\n",
    "            #Don#t forget the weighting\n",
    "            p = w_A*(p_single[c1] + p_single[c2])*similarity_c_c[c1,c2]\n",
    "            prob_strings.append(\"%f\"%p)\n",
    "        else:\n",
    "            prob_strings.append(\"0\")\n",
    "    #add dummy values to fill it up to number of keyslots\n",
    "    for i in range(len(keyslots) - len(characters)):\n",
    "        prob_strings.append(\"0\")\n",
    "    f.write(\" \".join(prob_strings) + \"\\n\")\n",
    "#add dummy values to fill it up to number of keyslots\n",
    "for i in range(len(keyslots) - len(characters)):\n",
    "    prob_strings = []\n",
    "    for c2 in characters:\n",
    "        prob_strings.append(\"0\")\n",
    "    #add dummy values to fill it up tp number of keyslots\n",
    "    for i in range(len(keyslots) - len(characters)):\n",
    "        prob_strings.append(\"0\")\n",
    "    f.write(\" \".join(prob_strings) + \"\\n\")\n",
    "\n",
    "#write the w_A weighted distances with linear cost added on diagonal\n",
    "f.write(\"# distances\\n\")\n",
    "distances = distance_level_0\n",
    "\n",
    "for s1 in keyslots:\n",
    "    dist_strings = []\n",
    "    for s2 in keyslots:        \n",
    "        d = distances[(s1,s2)]\n",
    "        dist_strings.append(\"%f\"%d) \n",
    "        \n",
    "    f.write(\" \".join(dist_strings) + \"\\n\")\n",
    "\n",
    "f.write(\"# fixation of the spacebar to the bottom\\n\")\n",
    "f.write(\"0\\n\")\n",
    "f.write(\"# scale for rounding down the probabilities\\n\")\n",
    "f.write(\"1e6\")\n",
    "f.write(\"# distances\\n\")\n",
    "distances = distance_level_0\n",
    "\n",
    "for c in characters:\n",
    "    lin_strings = []\n",
    "    for s in keyslots:        \n",
    "        l = linear_cost[(c,s)]\n",
    "        lin_strings.append(\"%f\"%l) \n",
    "        \n",
    "    f.write(\" \".join(lin_strings) + \"\\n\")\n",
    "#add dummy values to fill it up to number of keyslots\n",
    "for i in range(len(keyslots) - len(characters)):\n",
    "    lin_strings = []\n",
    "    for s in keyslots:\n",
    "        lin_strings.append(\"0\")    \n",
    "    f.write(\" \".join(lin_strings) + \"\\n\")\n",
    "    \n",
    "f.close()\n",
    "print \"Done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0065385393323679e-07"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_bigram[u'´d', u'z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16900"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(keyslots)*len(keyslots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5184"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "72*72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from read_input import * \n",
    "get_ergonomics()[u'D01', u'E00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read in: characters, keyslots and letters\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
